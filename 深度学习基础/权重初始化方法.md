### 权重初始化方法

在深度学习中，神经网络的权重初始化方法对模型的收敛速度和性能有着至关重要的影响。一个好的权重初始化虽然不能完全解决梯度消失和提付爆炸问题， 但是对于处理这两个问题是有很大帮助的， 并且十分有利于模型性能和收敛速度。

常见的权重初始化方法有5种：

* 权重初始化为0
* 权重随机初始化
* $Xavier$ $initialization$
* $He$ $initialization$
* 预训练权重



#### 1、权重初始化为0

如果将权重初始化全部为$0$的话， 这样的操作等同于等价于一个线性模型， 将所有权重设置为$0$时， 对于每一个$w$而言， 损失函数的导数都是相同的， 因此在随后的迭代过程中所有权重都具有相同的值， 这会使得隐藏单元变得对称， 并继续运行设置的n次的迭代， 会导致网络中同一神经元的不同权重都是一样的， 下面代码为权重初始化为$0$的代码：


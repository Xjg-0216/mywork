### 单机多卡并行计算



具体参考 https://blog.csdn.net/sinat_37532065/article/details/108510062

一个机器上可以安装多个`GPU``(1-16）`

在训练和预测时， 我们将一个小批量计算切分到多个`GPU`上来达到加速目的。

常用切分方案有：

* 数据并行
* 模型并行
* 通道并行（数据+模型并行）

**数据并行**

将小批量分成n块， 每个`GPU`拿到完整参数计算一块数据的梯度。(**通用性能更好**)

**模型并行**（类似流水线）

将模型分为`n`块， 每个`GPU`拿到一块模型计算它的前向和方向结果（**通常用于模型大到单`GPU`放不下**）

**数据并行**

1、读一个数据块（将样本切成N块， 每个`GPU`读一个数据块）

2、拿回参数

3、计算梯度 （每块`GPU`用完整的参数， 使用自己那部分的数据， 来计算梯度）

4、发出梯度（将每`GPU`上计算的梯度， 发到`key_value store`，在这里取平均并更新梯度）

5、上述过程就完成了一个梯度更新的过程（类似一个`batch`内的数据）

#### DataParallel

单进程， 多线程

```python
import torch
from torch import nn as nn
#构造模型
net = model(input_size, output_size)
#模型放在GPU上
net = net.cuda()
net = nn.DataParallel(net)
#数据放在GPU上
inputs, labels = inputs.cuda(), labels.cuda()
result = net(inputs)
```

如果不设定好要使用的device_ids的话， 程序会自动找到这个机器上面可以用的所有的显卡用于训练。

如果想要限制使用的显卡数：

```python
os.environ['CUDA_VISIBLE_DEVICES'] == '0, 5'
#限制代码能看到的GPU个数， 这里表示指定只使用实际的0号和5号GPU

#这时候device_count = 2
device_ids = range(torch.cuda.device_count())
#device_ids = [0, 1]这里的0就是上述指定的0号卡， 1对应的就是5号卡
net = nn.DataParallel(net, device_ids)
```

#### DisttibutedDataParallel

DDP支持单机多卡和多机多卡， 这就涉及到进程通信， 多进程通信初始化， 是DDP使用最复杂的地方。

```python
torch.distributed.init_process_group()
```

常见参数

* backend： 后端， 实际上是多个机器之间交换数据的协议， 官方推荐使用"nccl"作为backend
* init_method：机器之间交换数据需要指定一个主节点， 这个参数用来指定主节点的。（如果是单机多卡的话， 就是一个节点（机器））
* world_size: 参与job的进程数， 实际就是GPU的个数
* rank: 进程组中每个进程的唯一标识符。比如一个节点8张卡， world_size为8， 每张卡的rank是对应的0-7的整数
* local_rank： 假设有两个节点/机器， 每个节点有8张卡， 总共16张卡， 对应16个进程， global rank是指0-15， 对于节点1， local_rank为0-7， 对于节点2， local_rank也是0-7

单机多卡的torch中DDP的使用如下方式：

```python
import os 
import torch
import re
import torch.nn as nn
import torch.distributed as dist
from torch.nn.DataParallel import DistributedDataParallel as DDP

#1、获取环境信息
rank = int(environ['SLURM_PROCID']) # 可用作全局rank
world_size = int(os.environ['SLURM_NTASKS'])  # 可用作world size
local_rank = int(os.environ['SLURM_LOCALID']) # local_rank
node_list = str(os.environ['SLURM_NODELIST']) #从中取得一个ip作为通讯ip
#2、对ip进行操作
node_parts = re.findall('[0-9]+', node_list)
host_ip = '{}.{}.{}.{}'.format(node_parts[1], node_parts[2], node_parts[3], node_parts[4])
#注意端口一定要没有被使用
prot = '23456'
#使用TCP初始化方法
init_method = 'tcp://{}:{}'.format(host_ip, port)
#多进程初始化，初始化通信环境
dist.init_process_group("nccl", init_method=init_method, world_size=word_size, rank=rank)
#指定每个节点上的device
torch.cuda.set_device(local_rank)
model = model.cuda()

#当前模型所在local_rank
model = DDP(model, device_ids= [local_rank])
input = input.cuda()
output= model(input)
```

